{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Jupyter notebook notes ](https://medium.com/game-of-data/12-things-to-know-about-jupyter-notebook-markdown-3f6cef811707/)\n",
    "\n",
    "# Numpy Vs. PyTorch\n",
    "\n",
    "numpy **array** and pytorch **tensor** can be creted in hte same way: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = np.linspace(0,1,5)\n",
    "t = torch.linspace(0,1,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "They can be resised in similar ways"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = np.arange(48).reshape(3,4,4)\n",
    "t = torch.arange(48).reshape(3,4,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most imporantly they have the same broadcasting rules. In order to use **pytorch** (and **numpy**) most efficiently, one needs to have a very strong grasp of the **broadcasting rules**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General  Broadcasting Rules\n",
    "\n",
    "When operating on two arrays, Numpy compares their shapes element-wise. It starts with the trailing(i.e. rightmost) dimensions and works its way left. Two dimensions are compatible when \n",
    "1. they are equal\n",
    "2. one of them is 1\n",
    "\n",
    "**Example**: The following are compatible\n",
    "\n",
    "Shape 1:(1,6,4,1,7,2)\n",
    "\n",
    "Shape 2:(5,6,1,3,1,2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.ones((6,5))\n",
    "b = np.arange(5).reshape((1,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 2., 3., 4., 5.],\n",
       "       [1., 2., 3., 4., 5.],\n",
       "       [1., 2., 3., 4., 5.],\n",
       "       [1., 2., 3., 4., 5.],\n",
       "       [1., 2., 3., 4., 5.],\n",
       "       [1., 2., 3., 4., 5.]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a+b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.ones((6,5))\n",
    "b = torch.arange(5).reshape(1,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a+b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The arrays/tensors don't even have to have the same numbe of dimentions. If one of them has less dimentions than the other\n",
    "\n",
    "**Example**: Sacling each other the color channels of an image by a different amount:\n",
    "\n",
    "    Image  (3d array): 256 x 256 x 3\n",
    "    Scale  (1d array):             3\n",
    "    Result (3d array): 256 x 256 x 3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "Scale = torch.tensor([0.5,1.5,1])\n",
    "Image = torch.randn((256,256,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "Result = Image*Scale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example**:One has an array of 2 images and wants to scale the color channels of each image by a slightly different amount:\n",
    "\n",
    "    Images  (4d array): 2 x 256 x 256 x 3\n",
    "    Scales  (4d array): 2 x   1 x   1 x 3\n",
    "    Results (4d array): 2 x 256 x 256 x 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "Images = torch.randn(2,256,256,3)\n",
    "Scale = torch.tensor([0.5,1.1,0.7,0.6,0.3,0.9]).reshape(2,1,1,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "Results = Images*Scale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Operation across Dimentions\n",
    "\n",
    "fundomental thing for pytorch. Simple operations can be done one 1 dimentional tensors:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(5.8333), tensor(6.4485), tensor(13.), tensor(0.5000))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.tensor([0.5,13,4])\n",
    "torch.mean(t), torch.std(t), torch.max(t), torch.min(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suposing we have  a 2d sensor and we want to compute the mean value of each of the collumns.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 8.,  9., 10., 11.], dtype=torch.float64)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.arange(20, dtype=float).reshape(5,4)\n",
    "torch.mean(t, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.rand(5,256,256,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take the mean value across the batch(size 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([256, 256, 3])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mean(t,axis=0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "take mean across the color channel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torch.mean(t,axis=-1).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take only the maximum color channel value(and get corresponding indices):\n",
    "\n",
    "- This is done all the time in segmentation models(i.e take an image, decide which pixels coorespod to, say a car)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "values, indices = torch.max(t,axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 256, 256])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch vs Numpy Differences\n",
    "\n",
    "**Pytorch** starts to differ from numpy in terms of automatically computing gradients of operations\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(917., grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([[5.,8.],[4.,6.]], requires_grad=True)\n",
    "y = x.pow(3).sum()\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 75., 192.],\n",
       "        [ 48., 108.]])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.backward() #compute the gradient\n",
    "x.grad #print the gradient(everything that has happened to x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The automatic computation of gradients is the backbone of training deep learning models. Most gradient computations don't have an analytical formula, so the automatic computation of gradients is essential. In general if one has y = F(x)\n",
    "\n",
    "Then pytorch can compute dy/dxi For each element of the vector x. In the context of machine learning, x contains all the weights(parameters) of the neural network and y is the ***Loss Function*** of the neural network.\n",
    "\n",
    "# Additional benefits \n",
    "\n",
    "***In addition, Any sort of large matric multiplication problem is faster with toch tensor than with numpy arrays, especially when runnig in gpu***\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = torch.rand((1000,1000))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
